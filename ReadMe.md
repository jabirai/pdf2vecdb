````markdown
# ğŸ“„ Document Embedding & Vector Search Pipeline

A modular pipeline for ingesting internal PDFs (including scanned documents), extracting text, chunking content, generating vector embeddings using OpenAI, and storing them in a vector database (FAISS) for semantic search.

---

## ğŸš€ Features

- âœ… Supports both native and scanned PDFs  
- ğŸ§  OCR via OpenAI GPT-4 Vision (for scanned/image-based documents)  
- ğŸ“š Text chunking using LangChain's `RecursiveCharacterTextSplitter`  
- ğŸ” Embedding generation using OpenAI's `text-embedding-3-small`  
- ğŸ’¾ Vector storage with FAISS  
- ğŸ–¥ï¸ Streamlit front-end for quick interaction (optional)  
- ğŸ“ Batch PDF processing supported  

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ .env                        # OpenAI API keys and config variables
â”œâ”€â”€ .gitignore                 
â”œâ”€â”€ app.py                     # Streamlit interface (optional UI)
â”œâ”€â”€ config.py                  # Central configuration
â”œâ”€â”€ create_db.py               # Main pipeline to process PDFs and build FAISS DB
â”œâ”€â”€ embedding_pipeline.py      # Chunking & embedding logic
â”œâ”€â”€ key_checker.py             # Validates API key availability
â”œâ”€â”€ pdf_processor.py           # OCR and PDF loading logic
â”œâ”€â”€ ReadMe.md                  # This file
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ utils.py                   # Helper functions
````

---

## ğŸ› ï¸ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/your-repo-name.git
cd your-repo-name
```

### 2. Create & Activate Virtual Environment

```bash
python -m venv venv
source venv/bin/activate    # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure Environment

Create a `.env` file with your OpenAI API key and model config:

```
OPENAI_API_KEY=your-key-here
openai_model=gpt-4-vision-preview
embedding_model=text-embedding-3-small
chunk_size=500
chunk_overlap=50
dpi=300
pdfs_folder=./pdfs
db_path=./faiss_index
maxtokens=1000
```

---

## ğŸ“¦ Usage

### â–¶ï¸ Option 1: Run the Pipeline

Process all PDFs in the configured folder and store embeddings:

```bash
python create_db.py
```

### â–¶ï¸ Option 2: Launch Streamlit App (if available)

```bash
streamlit run app.py
```

---

## ğŸ§ª Example Flow

1. Load and OCR PDFs from `/pdfs` folder
2. Chunk extracted text into 500-token segments
3. Generate vector embeddings via OpenAI
4. Store vectors locally using FAISS
5. (Optional) Use Streamlit UI to query/search

---

## ğŸ§° Tech Stack

* **LangChain**
* **OpenAI API** (GPT-4 Vision + Embeddings)
* **PyMuPDF (`fitz`)**
* **FAISS**
* **Streamlit** (for UI)

---

## ğŸ“Œ Notes

* OCR is only triggered if PDF is image-based or loading fails.
* Supports both programmatic and UI-driven workflows.
* Easily extendable to use cloud vector stores like Pinecone.

---

## ğŸ“„ License

MIT License. See `LICENSE` file for details.

---

## ğŸ™‹â€â™‚ï¸ Author

**Jabir**
For queries, reach out via email or GitHub issues.

```

